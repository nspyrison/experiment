---
title: "Communicating human related spatial distributions: A comparison of spatial visualisations using visual inference."
affiliation:
  author-columnar: true         ## one column per author
  #institution-columnar: true  ## one column per institution (multiple autors eventually)
  # wide: true                  ## one column wide author/affiliation fields
  institution:
    - name: Queensland University of Technology
      department: Science and Engineering Faculty
      location: Brisbane, Australia
      email: stephanie.kobakian@qut.edu.au
      mark: 1
      author:
        - name: Stephanie Kobakian
    - name: Monash University
      department: Econometrics and Business Statistics Faculty
      location: Melbourne, Australia
      email: dicook@monash.edu
      mark: 1
      author:
        - name: Dianne Cook
keywords: ["statistics", "visual inference", "geospatial", "population"]
abstract: |
  Choosing a visualisation method may seem to be a simple task. The choropleth map display is commonly used for communicating spatial data. The visualisation method used to present geospatial data will influence the information derived by map users. Choosing an alternative display will influence the communication of the distribution. The hexagon tile map is presented as an alternative display. Visual inference is used to measure the power of design. The choropleth is used as a comparison point. The hexagon tile map display is an effective visualisation for communicatin=g population related distributions. The hexagon tile map display also allowed identification of the geographic distribution with values monotonically decreasing from North West toward South East areas of Australia.
dev: png
bibliography: mybibfile.bib
output: rticles::ieee_article
editor_options: 
  chunk_output_type: inline
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  error = FALSE, 
  message = FALSE)
```

```{r libraries}
# Load Libraries
library(tidyverse)
library(cowplot)
library(png)
library(grid)
library(lubridate)
library(broom)
library(readxl)
library(lme4)
library(ggthemes)
library(RColorBrewer)
library(visreg)
library(emmeans)
library(kableExtra)
```

Introduction
=============
<!-- no \IEEEPARstart -->
<!-- (should never be an issue) -->

<!-- General: comparison of displays, motivate hexagon tile map, enough info to motivate aims -->
<!-- geographies on choropleth -->
A geographic map base is commonly used to present geospatial statistics.
The statistics presented may also be aggreagated statistics for geographic units, in this case the choropleth map is the common display used. Choropleth maps are often used to present statistics regarding the population. 
Creating a choropleth map involves drawing the administrative boundaries and filling them with colour to communicate the value of the statistic. 
The several sets of Australian statistical areas presents an example of a heterogrenous distribution.
The rural communities in Australia operate on a much larger geographic space than small inner city communities.
This has the negative effect of incorrectly showing the spatial distribution of the statistic, especially when a spatial distribution is related to the size of the areas, or the population density.
An alternative display can be used to effectively communicate a spatial distribution for a set of heterogeneous areas.


Motivation
=============

<!-- Find a new display for the Cancer Atlas -->

## The Australian Cancer Atlas

The Australian Cancer Atlas is an online interactive web tool created to explore the burden of cancer on Australian communities. There are many cancer types presented, and they can be explored on an individual or aggregate level. 
The Australian communities are examined at the Statistical Areas at Level 2 (SA2) [@abs2016] used by the Australian Bureau of Statistics. Bayesian spatial smoothing has been applied to incorporate the value of the statistics of the neighbouring areas. Spatial smoothing allows for the protection privacy and gives stability to the estimates. The statistics mapped are the diagnoses (Standardised Incidence Rates) and excess deaths for each SA2, communicated as the difference from the Australian average of the statistics. The values of the statistic for each geographic area is communicated through the colour used to fill the areas, the colours are chosen for the diverging colour scheme. 
The Australian Cancer Atlas communicates the trends in the distributions of cancer over geographic space. It uses a choropleth map display and diverging colour scheme to draw attention to relationships between neighbouring areas. 


Background
=============


## Population focussed displays

Spatial visualisations communicate the distribution of statistics over geographic space. The most common display for spatial data is the choropleth map. However, the issue of using a choropleth map base becomes obvious when considering population related distributions.
Map creators have the ability to present spatial statistics in alternative displays that can highlight the population.
This work aims to show that a hexagon tile map display is a viable alternative to the geographic map base for presenting population statistics.
When presenting population statistics on a geographic map base, the size of the regions can allow errornous conclusions to be drawn about the state of the statistic over the entire population.
This occurs as large regions filled with a consistent colour or pettern can draw the attention of map readers, and small regions are not paid equal attention.
A choropleth map is not the only display that can be used for presenting geospatial data. 
Alternative maps include various cartograms, and tesselated tile maps. They allow other variables to be included in the display to highlight the staistical values of various geographic areas.

<!-- Cartogram -->

A cartogram transforms the geographic map base. The transformation begins with a choropleth map base, and the associated populations. There are several algorithms for transforming, they all involve shifting boundaries to increase or descrease the area of the geographic units on the map depending on the statistics.
<!-- Why not a cartogram-->
The shifts of the boundaries result in cartograms with accurate map area for each of the geographic units. The transformation will keep boundaries of neighbouring areas connected, but the result is unfamiliar shapes for each geographic unit. 

<!-- Tesselated tile gram & hexagon tile map-->
Alternative displays make the trade off between familiar shapes and representation of variables using the area of geographic units. The non-contiguous cartgoram method keep the shapes of geographic units intact, and change the size to communicate the values of statistics. This method breaks the spatial relationship between areas, and emphasises the difference between the statistic and the amount of land for each geographic unit.
The Dorling cartogram is another method that does not retain the boundaries of geographic units. Each unit becomes one circle on the cartogram dispaly, these can be sized according to the value of a variable. Their neighbours can be illustrated by connecting the boundaries of the circles.
These cartogram methods all allow two variables to be shown in the single display.

```{r liver, fig.height = 9, fig.width = 6, fig.cap = "The smoothed average of liver cancer diagnoses for Australian males. The divering colour scheme shows dark blue areas with much lower than average diagnoses, yellow areas with diagnoses around the Australian average, orange with above average and red shows diagnoses much higher than average."}
ggdraw(ylim = c(0,2), xlim = c(0,1.3), clip = "on") +
  draw_plot(rasterGrob(readPNG("figures/aus_liver_m.png")), -0.15, 0.9, 1.6, 1.2) +
  draw_plot(rasterGrob(readPNG("figures/aus_liver_m_hex.png")), -0.15, -0.1, 1.6, 1.2) +
  draw_plot_label(c("a", "b"), 
    c(0.05, 0.05), c(1.95, 1), size = 20, color = "white") + 
  theme(plot.background = element_rect(fill = "black"))
```

<!-- Specific problem for Australia -->
Australia is an extreme case of heterogenous geographic units.
To communicate information regarding the small inner city geographic units of Australian cities an alternative display must be employed. This will emphasise the value of the statistic that is relating to areas with high population levels. Figure \@ref(fig:liver) shows the distribution of the smoothed average amount of Liver cancer diagnoses for Australian Males from XXX years. The hexagon tile map (b) shows orange hexagons for the inner city Statistical Areas at Level 2 with higher than average levels of diagnoses in the capital cities of Melbourne and Sydney.
These inner city areas are not visible on the choropleth map (a). There are still many light blue areas in both displays. The northern Queensland, and Northern Territory SA2's with higher than average rates are still visible but utilise less map space on the hexagon tile map.


## Methodology 

To test the 

## Visual Inference
- Communicating data through visualisations
- Effective displays for types of data
- Protocol for testing the effectiveness


The same data were shown on a choropleth map, and on a hexagon tile map.
Comparing the results of participants who see the choropleth to those who see a hexagon tile map will show that population related distributions are spotted more frequently in a hexagon tile map display.

Classical statistical inference involves hypothesis testing, the process of rejecting a null hypothesis in favour of an alternative. This approach relies on data, the appropriate distributions and their assumptions. 
Visual inference null hypothesis: independence in the variables (absence of all features), alternative hypothesis: Relationship between the variables (presence of some feature).
<!--
GTPCCD
In visual inference, data plots are considered to be test statistics, and these are compared with plots of data generated from a null hypothesis using a lineup

The null hypothesis underlying a
lineup is that there is no real structure visible in the data plot, that any
patterns seen are consistent with randomness, or from a known model.
If the null hypothesis is true then the plot of the data will not be distinguishable
from the plots of null data.

Different lineups are created, using the same data, same null plots and
positions within the lineup, but different plot designs.

Comparing how
long viewers take and how accurately they report the feature of interest
will assess which design is better for the task.
-->

<!--
A null dataset
is a sample from the null distribution, i.e. an example of an innocent
dataset, and a null plot is a plot of a null dataset, showing what an
innocent might look like.

testing can be adapted to work visually instead of numerically.[@GIIV]
Graphical Inference for Infovis
Chloropleth maps Is there a spatial trend?

Simulation. We might be interested in a more specific set of hypothesis:
does time increase linearly with distance from target?
Does accuracy decrease exponentially as number of distractors
increases? In those cases we have a probabilistic model and we
can generate null data sets by sampling from the distribution implied
by the model. This approach is used in Section 4.2.
-->

The lineup protocol is used for visual inference testing.
1. simulate null plots 
2. Insert data with structure into a random location
3. Ask uninvolved person to select the most different plot
4. If location is chosen correctly, the existence of a feature is significant at $\alpha = 1/N$.



> "In this framework, plots take on the role of test statistics, and human cognition the role of statistical tests." @SIEDAMD

The line up protocol involves placing a "guilty" data visualisation in a lineup of "innocents". Where the guilty data set contains structure, and the innocents are equivalent to a null data set. 
In a grid of visualisations, an observer is asked to pick the display that is most different, if they select the data set containing structure, they have identified the guilty hidden within the group innocents.
The guilty data is identified as different from the innocent data with probability $1/m$, where $m$ is the number of null plots plus 1 to account account for the guilty data set. When the guilty data set is chosen, the null hypothesis that it was innocent is rejected with a $1/m$ chance or type I error of being wrong.

The lineup protocol can be used in a variety of testing scenarios. The choropleth map is best used for testing spatial structure in a data set.

<!--
The line-up protocol works like a police line-up: the suspect (test
statistic plot) is hidden in a set of decoys. If the observer, who has not
seen the suspect, can pick it out as being noticeably different, there is
evidence that it is not innocent.
-->
  


Study Design
============

This study aims to answer several questions around the presentation of spatial distributions:

1. Are spatial disease trends, that impact highly populated small areas, detected with higher accuracy when viewed in a hexagon tile map display?

2. Are people faster in detecting spatial disease trends, that impact highly populated small areas, when
using a hexagon tile map display?

additional considerations when completing this experimental task included exploration of the difficulty experienced by participants

<!--
 Do people find hexagon tile maps more difficult to read than choropleth maps?
 Are the reasons for choosing a plot different depending on the type of display?
-->

The mean of the detection rate for choropleth map, denoted as $\mu_C$, and the hexagon tile maps, $\mu_H$ will be contrasted. This leads to the following one sided hypothesis for this study:

$H_0$ : $\mu_H$ = $\mu_C$
$H_a$ : $\mu_H$ > $\mu_C$

The detection rate $\hat\pi$ is calculated as the amount of people that made the choice of plot that contained the real data, out of the participants who saw data plot in the lineup of the null data plots.

The difference in the detection rates for the two displays will be compared using the following:

$$ \hat\pi_C - \hat\pi_H \pm t_{1-\alpha,n-1}\sqrt{\hat\pi_C(1-\hat\pi_C)/n_C + \hat\pi_H(1-\hat\pi_H)/n_H} $$

## Experimental design


The most common display for spatial cancer data is the choropleth map.
This will be the comparative visualisation for presenting the lineups [@VVSIALM].
Most geographic distributions will have some degree of spatial autcorrelation between neighbours.
This feature will exist in all plots in the lineup displays, the plot that contains the trend feature shown in only one set of data will also be affected by spatial autocorrelation.
A reasonable amount of null plots $N-1$ in the lineup was chosen to ensure data is well hidden. For the detailed choropleth of Australian SA2 areas, we set $N = 12$ to not overwhelm participants.
A line up protocol was implemented to arrange 12 maps in each display. 
Individual displays were created by a combination of map type, and spatial trend model.


The hypotheses for each lineup are
$H_0$ : All plots look the same
$H_a$ : One plot looks different to the other plots 


Recruited participants to be uninvolved judges with no prior knowledge of the data to avoid discrimination or advantages.
The online crowdsource platform Figure-Eight was used to recruit participants. 

The researchers contrasted the different plot designs, as hexagon tilemap and geography in the lineups were created using the same data, and same null positions within the lineup.


Let $n$ be the number of independent observers and $x_i$ the
number of observers who picked plot $i$, $i = \{1,...,m\}$

Then $x_i, x_2, ..., x_m$ follows a multinomial
distribution$Mult_{\pi_1, \pi_2, ...., \pi_m}(x_i, x_2, ..., x_m)$ with 
$\sum_i \pi_i = 1$, where $\pi_i$ is the probability that plot $i$ is picked by an
observer, which we can estimate as $\hat{\pi}_i = x_i/n$.
The researchers compared the length of time taken, and the accuracy of the participants choices.
The power of a lineup can therefore be estimated as the ratio of correct
identifications $x$ out of $n$ viewings.

## The variables being manipulated and measured

The variables that were changed between groups were the type of plot shown and the trend model.

Each participant was randomly allocated to either Group A or Group B when they begun the survey. This resulted in 42 participants allocated to Group A, and 53 participants allocated to Group B.

    
The levels of the factors measured in the experiment were:
- Map type: *Choropleth, Hexagon tile*
- Trend: *Locations in three population centres, Locations in multiple population centres, South-East to North-West*

Factor combinations examined by each participant amount to 6 (2x3) lineup displays.
A participant did see the same data for both map types. Four simulated sets of data were generated for each treatment.
This will generate 24 lineups (12 were geographic maps, and 12 were hexagon tile maps). Participants will evaluate 12 lineups, 6 of each map type. Appendix A shows the experimental design visually.
For each of the six geographic displays and six hexagon displays, two of each trend model were shown to participants.

\begin{table}[]
\caption{The Experimental Design}
\label{tab:my-table}
\begin{tabular}{|l|l|l|}
\hline
Trend & Map type & Replicates \\ \hline
NW-SE & Choropleth & 2 \\ \hline
 & Hexagon tile & 2 \\ \hline
Three cities & Choropleth & 2 \\ \hline
 & Hexagon tile & 2 \\ \hline
All cities & Choropleth & 2 \\ \hline
 & Hexagon tile & 2 \\ \hline
\end{tabular}
\end{table}


The variables measured as a result of the changes were the probability of detection each display and the time taken to submit responses.
To measure the accuracy of the detections, the plot chosen for each lineup evaluated was compared to the position of the real spatial trend plot in the lineup. A correct result occurs when the chosen plot matches the position of the real plot, this was recorded in an additional binary variable; 1 = correct; 0 = incorrect.
High efficiency occurs when a small amount of time is taken to evaluate each lineup. This will be measured as the numeric variable measuring the length of time taken to submit the answers to the evaluation of each line up.

## Simulation process

The underlying spatial correlation model was created to provide spatial autocorrelation between neighbouring areas using the longitude and latitude values for the Statistical Areas.
formula = z ~ 1, locations = ~ longitude + latitude

Simulated spatially dependent data using the model on the centroids of each area, for 12 null plots in 12 lineups.

12 sets of data were created.
In these 12 sets of data, each of the 144 maps were smoothed several times to replicate the spatial autocorrelation seen in cancer data sets presented in the Australian Cancer Atlas.

For each of the 144 individual maps, the values attributed to each geographic area are rescaled to show a similar colour scale from deep blue to dark red within each map.

A random location was selected for each set of lineup data.
In this location, a trend model was overlaid on the null set of spatially correlated data.
Each set of lineup data was used to produce a choropleth maps and hexagon tile maps. These matched pairs were split between Group A and Group B.

## Participants

There were 95 participants involved in the study. 
We recruited participants using the Figure-Eight crowd source platform by advertising this survey to participants that fulfilled the following crtieria:

- level 2 or level 3 on the Figure-Eight Platform.
- at least 18 years old

Participants then selected our task from the list of tasks available to them.

Each participant was trained using three test displays orienting them to the evaluation task.
Participants then proceeded to the survey, this involved evaluating 12 displays.

## Experiment procudure and data collection

The participant answered demographic questions and provided consent before evaluating the lineups.

Demographics were collected regarding the study participants:
- Gender (female / male / other),
- Degree education level achieved (high school / bachelors / masters / doctorate / other),
- Age range (18-24 / 25-34 / 35-44 / 45-54 / 55+ / other)
- Lived at least for one year in Australia (Yes / No )

Participants then moved to the evaulation phase.
The set of images differed for Group A and Group B.
After being allocated to a group, each individual was shown the 12 displays in randomised order.

Three questions were asked regarding each display:
- Plot choice
- Reason
- Difficulty

After completing the 12 evaluations, the participants were asked to submit their responses.

Data was collected through a web application containing the online survey.
Each participant used the internet to access the survey.
The data collection took place using a secure link between the survey web application and the googlesheet used to store results. The application would first connect to the googlesheet using the googlesheets [@sheets] R package, and interacted again at the completion of the survey by adding the participant's responses to the 12 displays as 12 rows of data in the googlesheet.

## The methods of data analysis used
The data analysis methods used in order to analyse and collate the results included downloading the survey submissions and opening them into the analysis software R [@RCore].
   
For each of the 12 lineup displays the researchers calculated:
- accuracy: the proportion of subjects who detected the data plot
- efficiency: average time taken to respond

### Visualisations
Side-by-side dot plots were made of accuracy (efficiency) against map type, facetted by trend model type.

Similar plots were made of the feedback and demographic variables - reason for choice, reported difficulty, gender, age, education, having lived in Australia - against the design variables.

Plots will be made in R (R Core Team 2019), with the ggplot2 package (Wickham 2016).   
   
   
### Modeling


The results will be analysed using a generalised linear model, with a subject random effect to account for differences in individuals. There will be two main effects: map type and trend model, which gives the fixed effects part of the model to be

$$\widehat{y_{ij}} = \mu + \tau_i + \delta_j + (\tau\delta)_{ij}, ~~~ i=1,2; ~j=1,2,3$$

where $y_{ij} = 0, 1$ whether the subject detected the data plot, $\mu$ is the overall mean, $\tau_i, i=1,2$ is the map type effect, $\delta_j$ is the trend model effect.
We are allowing for an interaction between map type and trend model. As the response for whether the participant detected the data plot is binary, a logistic model is used. 


A similar model will be constructed for the efficiency, using a log time, and normal errors. 

The feedback and demographic variables will possibly be incorporated as covariates.

Computation will be done using R [@RCore], with the `lme4` package [@lme4].


## Limitations of the data collection

The demographics of the participants showed a skew towards male participants. 
The randomness of the group allocation also resulted in more participants being allocated to Group B. Due to the allocation of lineup displays the participants all saw six Choropleth displays and six Hexagon Tile Map displays.


Results
============

```{r data}
trend_colours <- c(
  "NW-SE" = "#B2DF8A",
  "Three Cities" = "#A6CEE3",
  "All Cities" = "#1F78B4")
  
type_colours <- c(
  "Choro." = "#fcae91",
  "Hex." = "#a50f15")

detect_f_colours <- c(
  "No" = "#66C2A5",
  "Yes" = "#FC8D62")

detect_colours <- c(
  "Detected? No" = "#66C2A5",
  "Detected? Yes" = "#FC8D62")

  # Downloaded data
d <- read_xlsx("data/experiment-export.xlsx", sheet=2) %>%
  filter(!is.na(contributor)) %>%
  mutate(contributor = factor(contributor))

# Check data set 
# Need to clean multiple entries, 48, 24
# remove duplicated entries due to submit button
d <- d %>% group_by(group, contributor, image_name) %>%
  slice(1) %>% ungroup() %>% 
  arrange(group, contributor, plot_order)

# Remove contributors who did not provide answers to most questions
keep <- d %>% count(contributor, sort = TRUE) %>% filter(n > 10)
d <- d %>% 
  filter(contributor %in% keep$contributor) %>%
  filter(contributor != "1234567890")

# Remove contributors who did not provide any choices
bad_contribs <- d %>% group_by(contributor) %>% 
  summarise(sum0 = sum(choice)) %>% 
  filter(sum0 == 0) %>% 
  pull(contributor)

d <- d %>% 
  filter(!(contributor %in% bad_contribs))


n_contributors <- d %>% count(contributor, sort=TRUE) %>% 
  summarise(n_contributors = length(contributor))

d <- d %>% mutate(certainty = factor(as.character(certainty),
  levels = c("1", "2", "3", "4","5"), ordered=TRUE))
```

The survey responses from participants were kept only if the participant submitted answers for all 12 displays. This resulted in 92 participants.

```{r reps}
replicate <- tibble(image_name = c("aus_cities_12_geo.png", "aus_cities_12_hex.png", 
                                   "aus_cities_3_geo.png", "aus_cities_3_hex.png",
                                   "aus_cities_4_geo.png", "aus_cities_4_hex.png",
                                   "aus_cities_9_geo.png", "aus_cities_9_hex.png",
                                   "aus_nwse_2_geo.png", "aus_nwse_2_hex.png",
                                   "aus_nwse_3_geo.png", "aus_nwse_3_hex.png",
                                   "aus_nwse_5_geo.png", "aus_nwse_5_hex.png",
                                   "aus_nwse_6_geo.png", "aus_nwse_6_hex.png",
                                   "aus_three_12_geo.png", "aus_three_12_hex.png",
                                   "aus_three_5_geo.png", "aus_three_5_hex.png",
                                   "aus_three_8_geo.png", "aus_three_8_hex.png",
                                   "aus_three_9_geo.png", "aus_three_9_hex.png"),
                    replicate = c(1, 1, 2, 2, 3, 3, 4, 4, 
                                  1, 1, 2, 2, 3, 3, 4, 4,
                                  1, 1, 2, 2, 3, 3, 4, 4))
# Add rep info to data
d <- d %>% left_join(., replicate, by = "image_name")
```

The contributors who gave various plot choices and reasons for the twelve displays were kept.
The contributors who detected no plots correctly were analysed further. Three of these contribuotrs gave no choices for any of the twelve displays. They were also removed for the rest of the analysis.

Of the 92 participants, 67 were male, and 25 female. Only two of the participants had lived in Australia before.
The education level achieved by the participants was 70 Bachelors or Masters degree.

# Accuracy

The detection rate for participants reporting the real data trend model is used to calculate the accuracy of the responses of participants.


```{r pdetection_group}
# Tidy for analysis
d <- d %>% 
  separate(image_name, c("nothing", "trend", "location", "type", "extra"), remove = FALSE) %>%
  select(-nothing, -extra) %>%
  mutate(location = as.numeric(location), 
    # detect measures the accuracy of the choice
         detect = ifelse(location == choice, 1, 0)) %>% 
  mutate(trend = case_when(
    trend == "nwse" ~ "NW-SE",
    trend == "cities" ~ "All Cities",
    trend == "three" ~ "Three Cities")) %>% 
  mutate(trend = fct_relevel(trend, "NW-SE","Three Cities","All Cities")) %>% 
  mutate(type = case_when(
    type == "hex" ~"Hex.",
    TRUE~"Choro.")) %>% 
    mutate(detect_f = factor(detect, levels = c(0,1), labels = c("Detected? No", "Detected? Yes")))

plots <- d %>% group_by(group, trend, type, location) %>%
  # pdetect measures the aggregated accuracy of the choices
  summarise(pdetect = length(detect[detect == 1])/length(detect)) 
```





```{r detection_compare, fig.cap = "The detection rates achieved by participants are contrasted when viewing the four replicates of the three trend models. Each point shows the probability of detection for the lineup display, the facets separate the trend models hidden in the lineup. The points for the same data set shown in a choroleth or haxgon tile map display are linked to show the difference in the detection rate."}
# Detectability rate for each lineup (image)
d_smry <- d %>% group_by(trend, type, replicate) %>%
  # pdetect measures the aggregated accuracy of the choices
  summarise(pdetect = length(detect[detect == 1])/length(detect)) %>%
  ungroup()

# Plot summary
ggplot(d_smry, aes(x=type, y=pdetect, colour = trend)) +
  geom_point(size = 3) +  
  geom_line(size = 1, aes(group = replicate)) +  
  facet_wrap(~trend) +  
  scale_colour_manual(values = trend_colours) +
  xlab("Type of areas visualised") +
  ylab("Detection rate") + 
  ylim(0,1) +
  guides(colour = FALSE)
```

The detection rates are usually higher when participants viewed the hexagon tile map displays. The difference was greater when viewing a three cities trend model. When the trend model affected all cities participants also detected the data display in the lineup of null plots more often. The North West to South East data plot was detected with similar rates when viewing the choropleth and  hexagon tile map displays, though for three of the replicates the participants detected the data display more often. 


```{r ttest}
# Numerical summary
diffs <- d_smry %>% spread(type, pdetect) %>%
  mutate(dif = `Hex.` - `Choro.`)

# Probability of detection using map types
test_dt <- t.test(pdetect ~ type, data = d_smry, alternative = "less")
```

A t-test shows the difference between the detection rates for the two types of displays.
The value of `r test_dt$p.value` shows that it is very unlikely the difference is due to chance. 

```{r desc_stats, results = "asis"}
types <- c("Choro.", "", "Hex.", "")

d %>% group_by(type, trend) %>%
  summarise(m = round(mean(detect),3),
    std.dev = paste0("(", round(sd(detect),2),")")) %>% 
  gather(stat, value, m, std.dev) %>% 
  pivot_wider(names_from = "trend", values_from = "value") %>% 
  arrange(type) %>% ungroup() %>% 
  mutate(Type = types) %>% select(Type, `NW-SE`, `Three Cities`, `All Cities`) %>%
  knitr::kable(., format = "latex", align = "lccc")
```

The probability of detection is explored for each of the combinations of trans and type of display. 

## Speed

The amount of time taken for a participants to submit a response is explored. 
The time considered was the amount of time it took for a participant to submit their choice of plot, the reason for their choice, and the perceived difficulty of the choice. The time was taken when each participant hit "Next".

The relationship between time taken to submit, and the correct detection by the participant of the real data display in a lineup is considered in Figure \@ref(fig:hist_height). The bimodal distributions are similar across the type of display and the trend model hidden in the real data plot.
The hexagon map displays have a peak for the group that took up to 5 seconds to submit a response. When viewing a choropleth map display, the second peak occured at around 20 seconds. The longest a participant took to respond was 60 seconds. 


```{r hist_height, fig.cap = "Six histograms show the distribution of the time taken to submit a response for each combination of trend and type of display. The time taken to evaluate each display is broken into five second windows. The height of the histogram bars show how many evaulations were submitted within each time window. The orange regions of the bars show the amount of correct detections, and the green regions are the amount of incorrect detections."}
ggplot(d %>% rename(Detected = detect_f), 
  aes(x = time_taken, fill = Detected, group = Detected)) + 
  scale_fill_manual(values = detect_colours) +
  geom_histogram(binwidth = 5, boundary = 0) +
  facet_grid(type ~ trend) + 
  theme(legend.position = "bottom") +
  labs(x = "Time taken (Seconds)", y = "Amount of evaluations")
```


```{r hist_fill, fig.cap = "The time taken to evaluate each display is broken into five second windows. The height of the histogram bars show the proportion of evaulations that were submitted within each time window."}
ggplot(d %>% rename(Detected = detect_f), 
  aes(x = time_taken, fill = Detected, group = Detected)) +  
  scale_fill_manual(values = detect_colours) +
  geom_histogram(binwidth = 5, boundary = 0, position = "fill") +
  facet_grid(type ~ trend) +
  labs(x = "Time taken (Seconds)", y = "Proportion of evaluations")

ggplot(d, aes(x = time_taken, colour = detect_f, group = detect_f)) +  
  scale_fill_manual(values = detect_colours) +
  geom_freqpoly(binwidth = 3) +
  facet_grid(type ~ trend) +
  scale_fill_manual(values = detect_colours) +
  labs(x = "Time taken (Seconds)", y = "Amount of evaluations") +
  guides(colour = FALSE)
```

The proportion of correct and incorrect responses within each 5 second time window. For the NW-SE distribution, it is equally likely that quick responders will be correct or incorrect. It is more likely that participants picked the correct response if they took longer to respond. For the Choropelth

However, these quick responders were likely to be either correct or incorrect. The quick responders viewing a choropleth display were unlikely to choose correctly, unless viewing a NW-SE trend model. 

The choropleth map displays that included a distribution of three cities was very difficult for participants. 


## Certainty

```{r certainty, fig.cap = "The amount of times each level of certainty was chosen by participants when viewing hexagon tile map or choropleth displays. Participants were more likely to choose a high certainty when considering a Choropleth map. The mid value of 3 was the default certainty, it was chosen most for the Hexagon tile map displays."}
d <- d %>% 
  mutate(certainty = as_factor(certainty)) %>% 
  mutate(replicate_f = as_factor(replicate)) 

ggplot(d %>% rename(Detected = detect_f), 
   aes(x = certainty, fill = Detected)) +  
  scale_fill_manual(values = detect_colours) +
  geom_bar() + facet_grid(type ~ trend) +
  theme(legend.position = "bottom")
```

Certainty levels are measured on a five point scale—they are subjective
assessments by the participant ‘How certain are you about your choice?’.


## Reason

```{r reason, fig.cap = "The amount of participants that selected each reason for their choice of plot when looking at each trend model shown in Choropleth and Hexagon Tile maps. The facets show whether or not the choice was correct."}
###########################################################
# Qualitative analysis of reason
d %>% 
  mutate(reason = ifelse(reason =="0.0", "no reason", reason)) %>% 
  mutate(Detected = gsub("Detected? ", "", detect_f)) %>% 
  group_by(trend, Detected, type) %>% 
  count(reason) %>% 
  mutate(prop = round(n/sum(n), 3), r_prop = paste0(reason, ":", prop)) %>% 
  top_n(1, n) %>% summarise(reasons = paste(reason, collapse=", ")) %>% 
  pivot_wider(names_from = c("Detected"), values_from = c("reasons")) %>% 
  arrange(trend, type) %>% 
  select(Trend = trend, `Map Type` = type,
    `Yes` = `Detected? Yes`, `No` = `Detected? No`) %>% 
  knitr::kable(., format = "latex") %>% kable_styling("striped") %>%
  add_header_above(c(" " = 2, "Detected:" = 2))
```

The most common choice made by participant was clusters, this response was expected when participants viewed the Hexagon display of the all cities and three cities distributions.


## Contributors

```{r contributors, fig.cap = "The probablity of detection acheived by the contributors in each group is shown by the points. Group B has a larger range and a smaller inter-quartile range. Group A and  both had 3 people who did not find any of the data maps in the displays."}
# Check contributor performance
contribs <- d %>% group_by(group, contributor) %>% 
  # pdetect measures the aggregated accuracy of the choices
  summarise(pdetect = mean(detect, na.rm = TRUE)) 

# Plot performance
contribs %>% ggplot(aes(x = group, y = pdetect)) + 
  geom_boxplot() + 
  geom_jitter(width = 0.1, height = 0, alpha = 0.7) + 
  ylab("Detection rate") + 
  ylim(0,1)
```



```{r choices, fig.cap = "Each facet is associated with one lineup, the height of the points show the proportion of the participants that made each choice when considering each lineup. The points coloured orange show the map which contained a trend model, these are the correct choices. The numbers differentiate the replicates of each trend model and type of map display. Participants were able to select 0 to indicate they did not want to choose a map.", fig.height = 12, fig.width=10}
d %>% 
  count(type, trend, choice, replicate, choice, detect_f) %>% 
  group_by(type, trend, replicate) %>% 
  mutate(prop = n/sum(n)) %>% 
  mutate(repl = paste("Rep:", replicate, ":\n", type,  sep = "")) %>%
  mutate(bottom = 0) %>% 
  ggplot() + 
  geom_point(aes(x = choice, y = prop, color = detect_f), size = 4) + 
  geom_segment(aes(x = choice, xend = choice,y = bottom, yend = prop, colour = detect_f), size = 1) +
  facet_grid(repl ~ trend, 
    drop = TRUE, as.table = TRUE, scales = "free_y") +
  labs(x = "Choice of plot in lineup", y = "Amount of choices") +
  scale_colour_manual(values = detect_colours) +
  scale_x_continuous(breaks = seq(from = 0, to = 12)) +
  scale_y_continuous(breaks = seq(from = 0.0, to = 1.0, by = 0.1)) +
  theme(legend.position = "bottom") + 
  guides(colour = FALSE, fill = FALSE) +
  theme(strip.text.y = element_text(angle = 0))
```

The choices made by participants are examined in Figure \@ref(fig:choices).
Participants were misled by the choropleth display, but not the hexagon display for all cities displays except (2). The maps with a North West to South East trend was chosen with much greater frequency in all displays. All of three cities displays, except (4), were detected in the hexagon display. All except one lineup had at least one participant select the correct map in the lineup as shown in Figure \@ref(fig:choices).


## Anomolies



## Modeling the difference

The likelihood of detecting the data plot in the lineup can be modelled using a generalized linear mixed effects model. 
The base R [@RCore] `glm()` function implements generalised linear models. The model used includes the two main effects map type and trend model, which gives the fixed effects model to be:


$$\widehat{y_{ij}} = \mu + \tau_i + \delta_j + (\tau\delta)_{ij} + \epsilon_{i,j}, ~~~ i=1,2; ~j=1,2,3$$

where $y_{ij} = 0, 1$ whether the subject detected the data plot, $\mu$ is the overall mean, $\tau_i, i=1,2$ is the map type effect, $\delta_j$ is the trend model effect. We are allowing for an interaction between map type and trend model. Because the response is binary, a logistic model is used. This model can account for each individual participants’ abilities as it includes a subject-specific random intercept. As each participant provides results from 12 lineups.

### Detection Rates

The model specifies a logistic link, this means the predicted values from the `glm` model should be back-transformed to fit between 0 and 1. They are transformed with the link specified below:


$$\mu = \frac{e^{\eta}}{1 + e^{\eta}}$$
$$\eta = f(\tau_i,\delta_j)$$



```{r modeling_glm1}
# Modelling 
glm1 <- glm(formula = detect ~ type * trend,
  family = binomial(link = "logit"), data = d)

preds <- predict(glm1, newdata = d, se=T)
pfit <- exp(preds$fit)/(1+exp(preds$fit))
se.bands.logit = tibble(upper = (preds$fit+2*preds$se.fit), lower = (preds$fit-2*preds$se.fit))
se.bands = exp(se.bands.logit)/(1+exp(se.bands.logit))

factors <- c("Design", "", "Trend", "", "Interactions", "")
terms <- c("Intercept", "Hex", "Three cities", "All cities", "Hex : Three cities", "Hex : All cities")

tidy(glm1) %>% 
  mutate(p.value = round(p.value, 4)) %>%
  mutate(sig = case_when(
    p.value <= 0.001 ~ "***", 
    p.value <= 0.01 ~ "**", 
    p.value <= 0.05 ~ "*", 
    p.value <= 0.01 ~ ".",
    TRUE ~ " ")) %>% 
  mutate(term = terms,
    factors = factors) %>% 
  select(`_` = factors, 
    terms = term, 
    Estimate = estimate, 
    Error = std.error, 
    Stat = statistic,
    p.value, sig) %>% knitr::kable(format = "latex", 
      align = "lrrrrl")
```


```{r}
d_glm <- d %>% select(group:certainty, detect, detect_f) %>%
  bind_cols(as_tibble(se.bands)) %>% 
  mutate(pfit, 
    predicted = ifelse(pfit > 0.5, 1, 0),
    predicted = factor(predicted, levels = c(0,1), 
      labels = c("Predicted: No", "Predicted: Yes")))

table(d_glm$predicted, d_glm$detect_f)
```

This gives the model:


$$\widehat{y_{ij}} = 0.0217 + 0.42Hex -3.25_{three} -1.24_{all} + 2.37{Hex.three} + 1.08{Hex.all} $$



```{r}
glm2 <- glm(formula = detect ~ type * trend + replicate_f,
  family = binomial(link = "logit"), data = d)

emmean2 <- emmeans(glm2, c("trend", "type", "replicate_f"),
                        type = "response")

int_2 <- confint(emmean2, by = c("type", "trend", "replicate_f"), adjust = "bonferroni")
int_2 %>% 
  ggplot(aes(x= replicate_f, y = prob, group = type)) + 
  geom_point(aes(col = type)) + 
  geom_line(alpha = 0.5, lty = "dashed") + 
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL, col = replicate_f), 
                width = 0.2) +
  facet_grid(trend ~ .) +
  ylab("Estimated Marginal Mean")
```




```{r}
# Mixed effects models
lmer1 <- lmer(detect ~ type*trend + (1|contributor), data = d)
lmer1_d <- augment(lmer1, d)

preds_lmer <- predict(lmer1, newdata = d)
pfit_lmer <- exp(preds_lmer)/(1+exp(preds_lmer))

glance(lmer1)
tidy(lmer1)

d_lmer <- d %>% select(group:certainty, detect, detect_f) %>%
  bind_cols(as_tibble(se.bands)) %>% 
  mutate(pfit_lmer, 
    predicted = ifelse(pfit_lmer > 0.5, 1, 0),
    predicted = factor(predicted, levels = c(0,1), labels = c("No", "Yes")))

table(d_lmer$predicted, d_lmer$detect_f)

# Hexagon maps have better chance of correct detection
# Allowing for contributor effects to vary: 0.12 strong residual
```


For a base model of Choropleth map, using a NW-SE trend model.
The detection rate for Hexagon tile maps using a NW-SE trend model changes the log odds of the detection by 0.42.

```{r}
# Mixed effects models
lmer2 <- lmer(detect ~ (type|trend), data = d)
lmer2_d <- augment(lmer2, d)

preds_lmer2 <- predict(lmer2, newdata = d)
pfit_lmer2 <- exp(preds_lmer2)/(1+exp(preds_lmer2))

glance(lmer2)
tidy(lmer2)

d_lmer2 <- d %>% select(group:certainty, detect, detect_f) %>%
  bind_cols(as_tibble(se.bands)) %>% 
  mutate(pfit_lmer2, 
    predicted = ifelse(pfit_lmer2 > 0.5, 1, 0),
    predicted = factor(predicted, levels = c(0,1), labels = c("No", "Yes")))

table(d_lmer2$predicted, d_lmer2$detect_f)
```


### Certainty

```{r}
# Modelling 
lm1 <- lm(formula = as.numeric(certainty) ~ type, data = d)
lm1_d <- augment(lm1, d)
```






```{r}
# Mixed effects models
lmer1 <- lmer(detect ~ type*trend + (1|contributor), data = d)
lmer1 

# Hexagon maps have better chance of correct detection
# Allowing for contributor effects to vary: 0.12 strong residual
```


Discussion
============



Conclusion
============
how do the results found generalise to other work
- Not just for Aus (Canada new Zealand could also use this effective display)

- For USA alternative methods can also be helpful

<!-- conference papers do not normally have an appendix -->

Supplementary Materials
============

## Training

## Survey application

## Overall Performance

```{r pdetection_trend, eval = FALSE}
plots %>% ggplot(aes(x = group, y = pdetect)) + 
  geom_boxplot() + 
  geom_jitter(width = 0.1) +
  ylab("Detection rate") + 
  ylim(c(0,1))

plots %>% ggplot(aes(x = trend, y = pdetect, fill = trend)) + 
  geom_boxplot() + 
  scale_fill_manual(values = trend_colours) +
  geom_jitter(width = 0.1) +
  ylab("Detection rate") + 
  ylim(c(0,1)) 

plots %>% ggplot(aes(x = type, y = pdetect)) + 
  geom_boxplot() + 
  geom_jitter(width = 0.1) +
  ylab("Detection rate") + 
  ylim(c(0,1))
```

## Subject specific anomolies (0% detection)

## Demographics:

```{r demogs}
# Create one record for each contributor, to examine demographics
dem_contribs <- d %>%
  group_by(contributor) %>%
  slice(1) %>% ungroup()

###############################################################################
# Demographics of contributors
#dem_contribs %>% count(gender)
dem_contribs %>% ggplot() + geom_bar(aes(age))
dem_contribs %>% count(gender)
dem_contribs %>% count(education)
dem_contribs %>% count(gender, education) %>% 
  spread(gender, n) %>% 
  mutate(`Col. Total` = He + She) %>% 
  gather("Gender", "Amount", He:`Col. Total`) %>% 
  spread(education, Amount) %>% 
  mutate(`Row Total` = Bach + `High School`, Masters,
    Gender = factor(Gender, levels = c("He", "She", "Col. Total"), labels = c("He", "She", "Col. Total"))) %>% knitr::kable(format = "latex")
```


Acknowledgment {#acknowledgment}
==============

The authors would like to thank...


Ethics approval for the online survey was granted by QUT’s Ethics Committee (Ethics Application Number: 1900000991). All applicants provided informed consent in line with QUT regulations prior to participating in this research. 


Bibliography styles
===================

\newpage
References {#references .numbered}
==========





<!-- An example of a floating figure using the graphicx package. -->
<!-- Note that \label must occur AFTER (or within) \caption. -->
<!-- For figures, \caption should occur after the \includegraphics. -->
<!-- Note that IEEEtran v1.7 and later has special internal code that -->
<!-- is designed to preserve the operation of \label within \caption -->
<!-- even when the captionsoff option is in effect. However, because -->
<!-- of issues like this, it may be the safest practice to put all your -->
<!-- \label just after \caption rather than within \caption{}. -->

<!-- Reminder: the "draftcls" or "draftclsnofoot", not "draft", class -->
<!-- option should be used if it is desired that the figures are to be -->
<!-- displayed while in draft mode. -->

<!-- \begin{figure}[!t] -->
<!-- \centering -->
<!-- \includegraphics[width=2.5in]{myfigure} -->
<!-- where an .eps filename suffix were assumed under latex,  -->
<!-- and a .pdf suffix were assumed for pdflatex; or what has been declared -->
<!-- via \DeclareGraphicsExtensions. -->
<!-- \caption{Simulation results for the network.} -->
<!-- \label{fig_sim} -->
<!-- \end{figure} -->

<!-- Note that the IEEE typically puts floats only at the top, even when this -->
<!-- results in a large percentage of a column being occupied by floats. -->


<!-- An example of a double column floating figure using two subfigures. -->
<!-- (The subfig.sty package must be loaded for this to work.) -->
<!-- The subfigure \label commands are set within each subfloat command, -->
<!-- and the \label for the overall figure must come after \caption. -->
<!-- \hfil is used as a separator to get equal spacing. -->
<!-- Watch out that the combined width of all the subfigures on a  -->
<!-- line do not exceed the text width or a line break will occur. -->

<!-- \begin{figure*}[!t] -->
<!-- \centering -->
<!-- \subfloat[Case I]{\includegraphics[width=2.5in]{box}% -->
<!-- \label{fig_first_case}} -->
<!-- \hfil -->
<!-- \subfloat[Case II]{\includegraphics[width=2.5in]{box}% -->
<!-- \label{fig_second_case}} -->
<!-- \caption{Simulation results for the network.} -->
<!-- \label{fig_sim} -->
<!-- \end{figure*} -->

<!-- Note that often IEEE papers with subfigures do not employ subfigure -->
<!-- captions (using the optional argument to \subfloat[]), but instead will -->
<!-- reference/describe all of them (a), (b), etc., within the main caption. -->
<!-- Be aware that for subfig.sty to generate the (a), (b), etc., subfigure -->
<!-- labels, the optional argument to \subfloat must be present. If a -->
<!-- subcaption is not desired, just leave its contents blank, -->
<!-- e.g., \subfloat[]. -->

